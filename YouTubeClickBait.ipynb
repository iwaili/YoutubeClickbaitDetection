{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install linearmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import YouTubeVideo\n",
    "from linearmodels.panel import PanelOLS, RandomEffects\n",
    "from linearmodels.panel.data import PanelData\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "!pip install transformers torch\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/kaggle/input/bollybait-detection/bollybait01.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Label'] == 'Real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "df1=pd.get_dummies(df[['Misleading Video','False Promises ', 'Exaggerated Video' ,'Spam Content ','Exploits Curiosity Gap :','Label']], dtype = int, drop_first =True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "label_counts = df['Label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Videos (Real vs. Misleading)')\n",
    "plt.axis('equal')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "attributes = ['Misleading Video','False Promises ', 'Exaggerated Video' ,'Spam Content ','Exploits Curiosity Gap :']\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "for i, attribute in enumerate(attributes, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    attribute_counts = df[attribute].value_counts()\n",
    "    plt.pie(attribute_counts, labels=attribute_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(f'Distribution of {attribute}')\n",
    "    plt.axis('equal')\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# df2= pd.merge(df, df1, on='Channel Title', how='left')\n",
    "# print(df2)\n",
    "# df1['Total Misleading Videos'] = df1[['Misleading Video_Yes','False Promises _Yes','Exaggerated Video_Yes','Spam Content _Yes','Exploits Curiosity Gap :_Yes']].sum(axis=1)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# sns.barplot(x='Channel Title', y='Total Misleading Videos', data=df)\n",
    "# plt.title('Total Misleading Videos by Channel ID')\n",
    "# plt.xlabel('Channel Title')\n",
    "# plt.ylabel('Sum of Misleading Videos')\n",
    "# plt.xticks(rotation=45) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "correlation_matrix = df1[['Misleading Video_Yes', 'False Promises _Yes', 'Exaggerated Video_Yes', 'Spam Content _Yes', 'Exploits Curiosity Gap :_Yes']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='Reds', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-api-python-client --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "dataset = pd.read_csv('/kaggle/input/bollybait-detection/bollybait01.csv')\n",
    "clickbait_titles = dataset[dataset['Label'] == 'Clickbait']['Title']\n",
    "text = ' '.join(clickbait_titles)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='black').generate(text)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "api_key = 'AIzaSyAusNcu91yrzYtxD7499b5wafk_pz7XHD8'\n",
    "video_id = 'LPSg2vQBvT4'\n",
    "\n",
    "video_info_url = f'https://www.googleapis.com/youtube/v3/videos?id={video_id}&key={api_key}&part=snippet,contentDetails,statistics'\n",
    "print(video_info_url)\n",
    "response = requests.get(video_info_url)  # GET request to the API endpoint to get video information\n",
    "\n",
    "if response.status_code == 200:\n",
    "    video_data = response.json()\n",
    "    video_info = video_data['items'][0]\n",
    "    video_title = video_info['snippet']['title']\n",
    "    video_description = video_info['snippet']['description']\n",
    "\n",
    "    # Use get method with a default value to handle missing keys\n",
    "    view_count = video_info['statistics'].get('viewCount', 0)\n",
    "    like_count = video_info['statistics'].get('likeCount', 0)\n",
    "    dislike_count = video_info['statistics'].get('dislikeCount', 0)\n",
    "    comment_count = video_info['statistics'].get('commentCount', 0)\n",
    "    # Use get method with a default value to handle missing keys\n",
    "    dislike_count = video_info['statistics'].get('dislikeCount', 'Dislikes not available')\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Title: {video_title}')\n",
    "    print(f'Description: {video_description}')\n",
    "    print(f'View Count: {view_count}')\n",
    "    print(f'Like Count: {like_count}')\n",
    "    print(f'Dislike Count: {dislike_count}')\n",
    "    print(f'Comment Count: {comment_count}')\n",
    "\n",
    "    def classify_video(view_count, like_count):\n",
    "        view_count = int(view_count) if str(view_count).isdigit() else 0\n",
    "        like_count = int(like_count) if str(like_count).isdigit() else 0\n",
    "        view_like_ratio = (view_count / like_count) if like_count != 0 else float('inf')\n",
    "        threshold = 124\n",
    "\n",
    "        if view_like_ratio < threshold:\n",
    "            return \"Real Video\"\n",
    "        else:\n",
    "            return \"Misleading Video\"\n",
    "\n",
    "    thumbnails = video_info['snippet']['thumbnails']\n",
    "    if 'maxres' in thumbnails:\n",
    "        maxres_thumbnail_url = thumbnails['maxres']['url']\n",
    "    else:\n",
    "        maxres_thumbnail_url = thumbnails['high']['url']\n",
    "\n",
    "    image_response = requests.get(maxres_thumbnail_url)\n",
    "\n",
    "    if image_response.status_code == 200:\n",
    "        image = Image.open(BytesIO(image_response.content))\n",
    "        image.save(f'{video_id}_maxres_thumbnail.jpg', 'JPEG')\n",
    "        print(f'Highest resolution thumbnail saved as {video_id}_maxres_thumbnail.jpg')\n",
    "    else:\n",
    "        print(f'Failed to download the highest resolution thumbnail. Status code: {image_response.status_code}')\n",
    "\n",
    "    captions_url = f'https://www.googleapis.com/youtube/v3/captions?part=snippet&id={video_id}&key={api_key}'\n",
    "    captions_response = requests.get(captions_url)\n",
    "\n",
    "    if captions_response.status_code == 200:\n",
    "        captions_data = captions_response.json()\n",
    "        captions_info = captions_data['items'][0]['snippet']\n",
    "\n",
    "        captions_language = captions_info['language']\n",
    "        captions_name = captions_info['name']\n",
    "        captions_download_url = captions_info['track']['trackContentId']\n",
    "\n",
    "        print(f'Captions Language: {captions_language}')\n",
    "        print(f'Captions Name: {captions_name}')\n",
    "        print(f'Captions Download URL: {captions_download_url}')\n",
    "    else:\n",
    "        print(f'No captions found for this video.')\n",
    "else:\n",
    "    print(f'Failed to retrieve video data. Status code: {response.status_code}')\n",
    "\n",
    "video_classification = classify_video(view_count, like_count)\n",
    "print(f'\\nPossible Video Classification: {video_classification}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "def get_youtube_comments(api_key, video_url, max_comments=20):\n",
    "    try:\n",
    "        video_id = video_url.split('=')[-1]\n",
    "        youtube = googleapiclient.discovery.build('youtube', 'v3', developerKey=api_key)\n",
    "        comments = []\n",
    "        while len(comments) < max_comments:\n",
    "            comments_response = youtube.commentThreads().list(\n",
    "                part='snippet',\n",
    "                videoId=video_id,\n",
    "                textFormat='plainText',\n",
    "                maxResults=min(100, max_comments - len(comments))\n",
    "            ).execute()\n",
    "\n",
    "            if 'items' in comments_response:\n",
    "                for item in comments_response['items']:\n",
    "                    comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "                    comments.append(comment)\n",
    "\n",
    "                if 'nextPageToken' in comments_response:\n",
    "                    comments_response = youtube.commentThreads().list(\n",
    "                        part='snippet',\n",
    "                        videoId=video_id,\n",
    "                        textFormat='plainText',\n",
    "                        pageToken=comments_response['nextPageToken'],\n",
    "                        maxResults=min(100, max_comments - len(comments))\n",
    "                    ).execute()\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return comments[:max_comments]\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "        return None\n",
    "\n",
    "api_key = 'AIzaSyASTdqtjhZF37c1mms6ROnLqaTNt0qSuuE' \n",
    "video_url = 'https://www.youtube.com/watch?v=LPSg2vQBvT4'  \n",
    "comments = get_youtube_comments(api_key, video_url, max_comments=20)\n",
    "\n",
    "if comments is not None:\n",
    "    print('Comments:')\n",
    "    for i, comment in enumerate(comments):\n",
    "        print(f'{i + 1}: {comment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "video_url = 'https://www.youtube.com/watch?v=LPSg2vQBvT4'\n",
    "\n",
    "yt = YouTube(video_url)\n",
    "audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "output_path = '/kaggle/working' \n",
    "file_name = \"video_audio\"  \n",
    "\n",
    "audio_stream.download(output_path=output_path, filename=file_name)\n",
    "\n",
    "audio_link = f\"{output_path}/{file_name}.mp4\"\n",
    "\n",
    "print(\"Audio extraction completed.\")\n",
    "print(\"Audio file link:\", audio_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "video_url = 'https://www.youtube.com/watch?v=LPSg2vQBvT4'\n",
    "yt = YouTube(video_url)\n",
    "video_stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "video_stream.download()\n",
    "print(f'Video downloaded: {yt.title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytube import YouTube\n",
    "\n",
    "input_folder = \"/kaggle/input/\"\n",
    "video_filename = \"/kaggle/working/\"+yt.title  # Update with the actual filename\n",
    "\n",
    "input_video_path = os.path.join(input_folder, video_filename)\n",
    "print(f'Video file path: {input_video_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "video_title = video_title\n",
    "\n",
    "sentiment_scores = sid.polarity_scores(video_title)\n",
    "\n",
    "\n",
    "compound_score = sentiment_scores['compound']\n",
    "\n",
    "if compound_score >= 0.05:\n",
    "    sentiment_label = 'Positive'\n",
    "elif compound_score <= -0.05:\n",
    "    sentiment_label = 'Negative'\n",
    "else:\n",
    "    sentiment_label = 'Neutral'\n",
    "\n",
    "    \n",
    "print(f'Title: {video_title}')\n",
    "print(f'Sentiment Score: {compound_score:.4f}')\n",
    "print(f'Sentiment Label: {sentiment_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "input_video = \"/kaggle/working/Salman Khan and Sonakshi Sinha marriage video  wedding ceremony  gift  NOOK POST.mp4\"\n",
    "output_pattern = \"keyframes_%03d.jpg\"\n",
    "intervals = [0.25, 0.5, 0.75]  # 25%, 50%, 75%\n",
    "\n",
    "for interval in intervals:\n",
    "    output_file = f\"keyframes_{int(interval * 100)}percent_%03d.jpg\"\n",
    "    \n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", input_video,\n",
    "        \"-vf\", f\"fps=1/{interval},select='isnan(prev_selected_t)+gte(t-prev_selected_t,{interval})'\",\n",
    "        \"-vsync\", \"vfr\",\n",
    "        \"-frames:v\", \"5\",\n",
    "        \"-q:v\", \"2\",\n",
    "        output_file\n",
    "    ]\n",
    "    subprocess.run(ffmpeg_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory_path = \"/kaggle/working/\"\n",
    "files = os.listdir(directory_path)\n",
    "\n",
    "keyframe_files = [file for file in files if 'keyframes' in file and file.endswith('.jpg')]\n",
    "\n",
    "print(\"Keyframe files:\")\n",
    "for file in keyframe_files:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = 'bert-base-multilingual-cased' #isme kayi saare versions/models hote hain\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "input_text = \"kill this bitch.\"\n",
    "tokens = tokenizer(input_text, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "predicted_class_index = torch.argmax(predictions).item()\n",
    "\n",
    "# Print the predicted class and its probability\n",
    "print(f\"Predicted Class: {predicted_class_index}\")\n",
    "print(\"Predicted Probabilities:\")\n",
    "for i, prob in enumerate(predictions.squeeze().tolist()):\n",
    "    print(f\"Class {i}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python opencv-python-headless face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import face_recognition\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# thumbnail_path = \"/kaggle/working/LPSg2vQBvT4_maxres_thumbnail.jpg\"\n",
    "# thumbnail_image = cv2.imread(thumbnail_path)\n",
    "# if thumbnail_image is None:\n",
    "#     print(f\"Failed to load thumbnail image from path: {thumbnail_path}\")\n",
    "#     exit()\n",
    "\n",
    "# thumbnail_rgb = cv2.cvtColor(thumbnail_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # Detect faces in the thumbnail\n",
    "# face_locations_thumbnail = face_recognition.face_locations(thumbnail_rgb)\n",
    "# face_embeddings_thumbnail = face_recognition.face_encodings(thumbnail_rgb, face_locations_thumbnail)\n",
    "\n",
    "# total_faces_thumbnail = len(face_locations_thumbnail)\n",
    "# total_faces_matched = 0\n",
    "\n",
    "# # Get the list of keyframe files\n",
    "# directory_path = \"/kaggle/working/\"\n",
    "# files = os.listdir(directory_path)\n",
    "# keyframe_files = [file for file in files if 'keyframes' in file and file.endswith('.jpg')]\n",
    "\n",
    "# for keyframe_path in keyframe_files:\n",
    "#     # Load the keyframe image\n",
    "#     keyframe_image = cv2.imread(os.path.join(directory_path, keyframe_path))\n",
    "#     if keyframe_image is None:\n",
    "#         print(f\"Failed to load keyframe image from path: {keyframe_path}\")\n",
    "#         continue\n",
    "\n",
    "#     keyframe_rgb = cv2.cvtColor(keyframe_image, cv2.COLOR_BGR2RGB)\n",
    "#     face_locations_keyframe = face_recognition.face_locations(keyframe_rgb)\n",
    "#     face_embeddings_keyframe = face_recognition.face_encodings(keyframe_rgb, face_locations_keyframe)\n",
    "\n",
    "#     if face_locations_thumbnail and face_locations_keyframe:\n",
    "#         # Convert face encodings to NumPy arrays\n",
    "#         np_embeddings_thumbnail = np.array(face_embeddings_thumbnail)\n",
    "#         np_embeddings_keyframe = np.array(face_embeddings_keyframe)\n",
    "\n",
    "#         # Adjust the tolerance level (e.g., 0.6 is the default, experiment with different values)\n",
    "#         tolerance = 0.6\n",
    "#         matches = face_recognition.compare_faces(np_embeddings_thumbnail, np_embeddings_keyframe, tolerance=tolerance)\n",
    "#         total_faces_keyframe = len(face_locations_keyframe)\n",
    "#         total_faces_matched += sum(matches)\n",
    "\n",
    "# if total_faces_thumbnail + total_faces_matched > 0:\n",
    "#     weight_w1 = (2 * total_faces_matched) / (total_faces_thumbnail + total_faces_matched)\n",
    "#     print(f\"Weight (W1): {weight_w1}\")\n",
    "# else:\n",
    "#     print(\"Weight (W1) is undefined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def calculate_weight_w1(total_faces_thumbnail, total_faces_keyframe, total_faces_matched):\n",
    "    if total_faces_thumbnail + total_faces_keyframe > 0:\n",
    "        weight_w1 = (2 * total_faces_matched) / (total_faces_thumbnail + total_faces_keyframe)\n",
    "        return weight_w1\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def detect_faces_and_embeddings(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Failed to load image from path: {image_path}\")\n",
    "        return None, None\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(rgb_image)\n",
    "    face_embeddings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "\n",
    "    return len(face_locations), face_embeddings\n",
    "\n",
    "thumbnail_path = \"/kaggle/working/LPSg2vQBvT4_maxres_thumbnail.jpg\"\n",
    "\n",
    "# Get the list of keyframe files\n",
    "directory_path = \"/kaggle/working/\"\n",
    "files = os.listdir(directory_path)\n",
    "keyframe_files = [file for file in files if 'keyframes' in file and file.endswith('.jpg')]\n",
    "\n",
    "total_faces_thumbnail, thumbnail_embeddings = detect_faces_and_embeddings(thumbnail_path)\n",
    "\n",
    "if total_faces_thumbnail is not None and thumbnail_embeddings is not None:\n",
    "    total_faces_matched = 1\n",
    "    \n",
    "    for keyframe_file in keyframe_files:\n",
    "        # Load the keyframe image\n",
    "        keyframe_path = os.path.join(directory_path, keyframe_file)\n",
    "        total_faces_keyframe, keyframe_embeddings = detect_faces_and_embeddings(keyframe_path)\n",
    "\n",
    "        if total_faces_keyframe is not None and keyframe_embeddings is not None and total_faces_keyframe > 0:\n",
    "            np_embeddings_thumbnail = np.array(thumbnail_embeddings)\n",
    "            np_embeddings_keyframe = np.array(keyframe_embeddings)\n",
    "            tolerance = 0.4  #affects the sensitivity of the face matching\n",
    "            matches = face_recognition.compare_faces(np_embeddings_thumbnail, np_embeddings_keyframe, tolerance=tolerance)\n",
    "            total_faces_matched += sum(matches)\n",
    "\n",
    "    weight_w1 = calculate_weight_w1(total_faces_thumbnail, total_faces_keyframe, total_faces_matched)+1\n",
    "\n",
    "    if weight_w1 is not None:\n",
    "        print(f\"Weight: {weight_w1}\")\n",
    "    else:\n",
    "        print(\"Weight is undefined.\")\n",
    "if(weight_w1>=1.75):\n",
    "    Spam_Content=0\n",
    "    \n",
    "else:\n",
    "    Spam_Content=1\n",
    "print(\"Spam Content:\", Spam_Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install cython\n",
    "!pip install opencv-python\n",
    "!pip install keras_retinanet opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/fizyr/keras-retinanet.git\n",
    "!cd keras-retinanet && pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir snapshots\n",
    "!wget https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5 -O snapshots/resnet50_coco_best_v2.1.0.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras_retinanet import models\n",
    "\n",
    "def preprocess_image(image):\n",
    "    return image\n",
    "\n",
    "def resize_image(image):\n",
    "    return image, 1.0\n",
    "\n",
    "def calculate_weight_w2(total_objects_thumbnail, total_objects_keyframe, total_objects_matched):\n",
    "    if total_objects_thumbnail + total_objects_keyframe > 0:\n",
    "        return 2 * total_objects_matched / (total_objects_thumbnail + total_objects_keyframe)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def detect_objects(image_path, model, class_labels):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "\n",
    "    confidence_threshold = 0.5\n",
    "    selected_indices = np.where(scores[0] > confidence_threshold)\n",
    "    boxes = boxes[0, selected_indices]\n",
    "    labels = labels[0, selected_indices]\n",
    "    print(selected_indices)\n",
    "    if labels.size > 0:\n",
    "        labels = [class_labels[int(label)] for label in labels[0]]\n",
    "    else:\n",
    "        print(\"No labels detected.\")\n",
    "        labels = []\n",
    "        \n",
    "    print(f\"Detected objects: {labels}\")\n",
    "    print(\"Object coordinates:\")\n",
    "    for box, label in zip(boxes, labels):\n",
    "        print(f\"{label}: {box}\")\n",
    "\n",
    "    return len(boxes), labels\n",
    "\n",
    "model_path = \"/kaggle/working/snapshots/resnet50_coco_best_v2.1.0.h5\"\n",
    "model = models.load_model(model_path, backbone_name=\"resnet50\")\n",
    "\n",
    "thumbnail_path = \"/kaggle/working/LPSg2vQBvT4_maxres_thumbnail.jpg\"\n",
    "directory_path = \"/kaggle/working/\"\n",
    "keyframe_files = [file for file in os.listdir(directory_path) if 'keyframes' in file and file.endswith('.jpg')]\n",
    "\n",
    "classes = [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "         'hair drier', 'toothbrush' ]\n",
    "\n",
    "total_objects_thumbnail, thumbnail_objects = detect_objects(thumbnail_path, model, classes)\n",
    "\n",
    "if total_objects_thumbnail is not None and thumbnail_objects is not None:\n",
    "    total_objects_matched = 0\n",
    "\n",
    "    for keyframe_file in keyframe_files:\n",
    "        keyframe_path = os.path.join(directory_path, keyframe_file)\n",
    "        total_objects_keyframe, keyframe_objects = detect_objects(keyframe_path, model, classes)\n",
    "\n",
    "        if total_objects_keyframe is not None and keyframe_objects is not None:\n",
    "        \n",
    "            common_objects = set(thumbnail_objects) & set(keyframe_objects)\n",
    "            total_objects_matched += len(common_objects)\n",
    "\n",
    "    weight_w2 = calculate_weight_w2(total_objects_thumbnail, total_objects_keyframe, total_objects_matched)\n",
    "\n",
    "    if weight_w2 is not None:\n",
    "        print(f\"Weight: {weight_w2}\")\n",
    "    else:\n",
    "        print(\"Weight is undefined.\")\n",
    "def check_misleading_video(weight):\n",
    "    if weight > 6:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 \n",
    "#weight_threshold = 6\n",
    "false_promises = check_misleading_video(weight_w2)\n",
    "print(f\"False Promises: {misleading_video}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def detect_objects(image_path, net, labels):\n",
    "#     image = cv2.imread(image_path)\n",
    "#     if image is None:\n",
    "#         print(f\"Failed to load image from path: {image_path}\")\n",
    "#         return None, None\n",
    "\n",
    "#     blob = cv2.dnn.blobFromImage(image, swapRB=True, crop=False)\n",
    "#     net.setInput(blob)\n",
    "#     detections = net.forward()\n",
    "\n",
    "#     objects = []\n",
    "#     for i in range(detections.shape[2]):\n",
    "#         confidence = detections[0, 0, i, 2]\n",
    "#         if confidence > 0.5:  # Confidence threshold\n",
    "#             class_id = int(detections[0, 0, i, 1])\n",
    "#             label = labels[class_id]\n",
    "#             objects.append(label)\n",
    "\n",
    "#     return len(objects), objects\n",
    "\n",
    "# # Path to the thumbnail image\n",
    "# thumbnail_path = \"/kaggle/working/LPSg2vQBvT4_maxres_thumbnail.jpg\"\n",
    "\n",
    "# # Path to the RetinaNet model file\n",
    "# model_path = \"/kaggle/working/snapshots/resnet50_coco_best_v2.1.0.h5\"\n",
    "\n",
    "# net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "\n",
    "# # Open and read labels file\n",
    "# labels_path = \"/kaggle/working/keras-retinanet/keras_retinanet/preprocessing/kitti.py\"\n",
    "# with open(labels_path, 'r') as f:\n",
    "#     labels = f.read().strip().split('\\n')\n",
    "\n",
    "# # Detect objects in the thumbnail\n",
    "# total_objects_thumbnail, thumbnail_objects = detect_objects(thumbnail_path, net, labels)\n",
    "\n",
    "# # Print the results\n",
    "# if total_objects_thumbnail is not None and thumbnail_objects is not None:\n",
    "#     print(f\"Total Objects in Thumbnail: {total_objects_thumbnail}\")\n",
    "#     print(f\"Objects: {thumbnail_objects}\")\n",
    "# else:\n",
    "#     print(\"Object detection failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import preprocess_image, resize_image\n",
    "from IPython.display import Image, display  \n",
    "\n",
    "\n",
    "model_path = \"/kaggle/working/snapshots/resnet50_coco_best_v2.1.0.h5\"\n",
    "model = models.load_model(model_path, backbone_name=\"resnet50\")\n",
    "\n",
    "image_path = \"/kaggle/working/LPSg2vQBvT4_maxres_thumbnail.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "image = preprocess_image(image)\n",
    "image, scale = resize_image(image)\n",
    "\n",
    "boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "\n",
    "boxes /= scale\n",
    "\n",
    "for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "    if score < 0.3: \n",
    "        continue\n",
    "\n",
    "    box = [int(x) for x in box]\n",
    "    cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "    cv2.putText(image, f\"Class {label}: {score:.2f}\", (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "output_image_path = \"/kaggle/working/object_detection_result.jpg\"\n",
    "cv2.imwrite(output_image_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "display(Image(filename=output_image_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights yolov5s.pt --img-size 640 --conf 0.25 --source /kaggle/working/LPSg2vQBvT4_maxres_thumbnail.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python detect.py --weights yolov5s.pt --img-size 640 --conf 0.25 --source /kaggle/working/keyframes_25percent_004.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "\n",
    "def lexical_features(title):\n",
    "    has_number = bool(re.search(r'\\d', title))\n",
    "    has_question_mark = '?' in title\n",
    "\n",
    "    emoji_count = emoji.emoji_count(title)\n",
    "\n",
    "    total_letters = sum(c.isalpha() for c in title)\n",
    "    capital_letters = sum(c.isupper() for c in title)\n",
    "    capital_letters_ratio = capital_letters / total_letters if total_letters > 0 else 0.0\n",
    "\n",
    "    punctuation_marks = re.findall(r'[.,?!]', title)\n",
    "    punctuation_count = len(punctuation_marks)\n",
    "\n",
    "    return {\n",
    "        'has_number': has_number,\n",
    "        'has_question_mark': has_question_mark,\n",
    "        'emoji_count': emoji_count,\n",
    "        'capital_letters_ratio': capital_letters_ratio,\n",
    "        'punctuation_count': punctuation_count\n",
    "    }\n",
    "\n",
    "def calculating_gap(has_number, has_question_mark, emoji_count, capital_letters_ratio, punctuation_count):\n",
    "    conditions_met = [has_number, has_question_mark, emoji_count > 4, capital_letters_ratio > 0.2989, punctuation_count > 4]\n",
    "\n",
    "    if sum(conditions_met) >= 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "video_title = \"WOW!! MUST WATCH!! AMAZING Video! Must Watch if you WANT TO WIN IN LIFE 100!! ðŸŽ‰\"\n",
    "features = lexical_features(video_title)\n",
    "\n",
    "exploits_curiosity_gap = calculating_gap(**features)\n",
    "\n",
    "for key, value in features.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(f\"\\nExploits_Curiosity_Gap: {exploits_curiosity_gap}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "celebrities_dictionary = ['Anushka Sharma', 'Kareena Kapoor', 'Shah Rukh Khan', 'Virat Kohli']\n",
    "\n",
    "def baitiness_analysis(baitiness_features):\n",
    "    counts_greater_than_zero = sum(1 for count in baitiness_features.values() if count > 0)\n",
    "    Spam_content = 1 if counts_greater_than_zero >= 3 else 0\n",
    "    return Spam_content\n",
    "\n",
    "def lexical_features_baitiness(title):\n",
    "    celebrity_mentions_count = sum(1 for celeb in celebrities_dictionary if celeb.lower() in title.lower())\n",
    "\n",
    "    slang_words = ['OMG', 'LOL', 'ROFL', 'WTF'] \n",
    "    slang_count = sum(1 for slang in slang_words if slang.lower() in title.lower())\n",
    "    porn_words = ['hot', 'sexy', 'nudes']  \n",
    "    porn_count = sum(1 for porn_word in porn_words if porn_word.lower() in title.lower())\n",
    "\n",
    "    bollywood_phrases = ['Casting couch', 'Nepotism', 'Pregnant', 'Marriage', 'Death', 'Movie', 'Wife', 'Divorce', 'Boyfriend', 'Girlfriend','viral'] \n",
    "    bollywood_phrases_count = sum(1 for phrase in bollywood_phrases if phrase.lower() in title.lower())\n",
    "\n",
    "    generic_phrases = ['10 Reasons Why', 'You wouldnâ€™t believe', 'Must Watch'] \n",
    "    generic_phrases_count = sum(1 for phrase in generic_phrases if phrase.lower() in title.lower())\n",
    "\n",
    "    return {\n",
    "        'celebrity_mentions_count': celebrity_mentions_count,\n",
    "        'slang_count': slang_count,\n",
    "        'porn_count': porn_count,\n",
    "        'bollywood_phrases_count': bollywood_phrases_count,\n",
    "        'generic_phrases_count': generic_phrases_count\n",
    "    }\n",
    "\n",
    "video_title = \"OMG! Anushka Sharma is now Married?? You wouldnâ€™t believe these 10 Reasons Why She AGREED LOL\"\n",
    "baitiness_features = lexical_features_baitiness(video_title)\n",
    "spam_content = baitiness_analysis(baitiness_features)\n",
    "\n",
    "for key, value in baitiness_features.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "    \n",
    "print(f\"\\nSpam_content: {spam_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_multi = df[\"Label\"]\n",
    "# x_multi = df.drop([\"Label\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x_multi, y_multi, test_size = 0.2, random_state = 42)\n",
    "# print(X_test)\n",
    "# print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1.drop([\"Label_Real\"], axis = 1), df1[\"Label_Real\"], test_size = 0.4, random_state = 12)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.4, random_state=12)\n",
    "lr_classifier = LogisticRegression()\n",
    "\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "y_pred = lr_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Logistic Regression Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.4, random_state=12)\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **K Nearest Neighbours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.4, random_state=12)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'KNN Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "model = RandomForestClassifier(random_state=12)\n",
    "model.fit(X_train, y_train)\n",
    "p = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, p)\n",
    "conf_matrix = confusion_matrix(y_test, p)\n",
    "classification_rep = classification_report(y_test, p)\n",
    "model.fit(X_train, y_train)\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "print(\"Test set accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_leakage = ['Misleading Video','False Promises ', 'Exaggerated Video' ,'Spam Content ','Exploits Curiosity Gap :','Label']  # List features suspected to cause leakage\n",
    "if set(potential_leakage) & set(X_test.columns):\n",
    "    print(\"Potential data leakage detected!\")\n",
    "else:\n",
    "    print(\"No data leakage detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1['Label_Real'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import time\n",
    "\n",
    "# Logistic Regression\n",
    "start_time = time.time()\n",
    "logreg_classifier = LogisticRegression(random_state=42)\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "fit_time_logreg = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "y_pred_logreg = logreg_classifier.predict(X_test)\n",
    "score_time_logreg = time.time() - start_time\n",
    "\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "f1_logreg = f1_score(y_test, y_pred_logreg)\n",
    "precision_logreg = precision_score(y_test, y_pred_logreg)\n",
    "recall_logreg = recall_score(y_test, y_pred_logreg)\n",
    "roc_auc_logreg = roc_auc_score(y_test, y_pred_logreg)\n",
    "\n",
    "# Naive Bayes\n",
    "start_time = time.time()\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "fit_time_nb = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "score_time_nb = time.time() - start_time\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "f1_nb = f1_score(y_test, y_pred_nb)\n",
    "precision_nb = precision_score(y_test, y_pred_nb)\n",
    "recall_nb = recall_score(y_test, y_pred_nb)\n",
    "roc_auc_nb = roc_auc_score(y_test, y_pred_nb)\n",
    "\n",
    "# K Nearest Neighbours\n",
    "start_time = time.time()\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "fit_time_knn = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "score_time_knn = time.time() - start_time\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "roc_auc_knn = roc_auc_score(y_test, y_pred_knn)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest\n",
    "start_time = time.time()\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "fit_time_rf = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "score_time_rf = time.time() - start_time\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"Fit Time: {fit_time_logreg}\")\n",
    "print(f\"Score Time: {score_time_logreg}\")\n",
    "print(f\"Accuracy: {accuracy_logreg}\")\n",
    "print(f\"F1 Score: {f1_logreg}\")\n",
    "print(f\"Precision: {precision_logreg}\")\n",
    "print(f\"Recall: {recall_logreg}\")\n",
    "print(f\"ROC-AUC: {roc_auc_logreg}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Naive Bayes:\")\n",
    "print(f\"Fit Time: {fit_time_nb}\")\n",
    "print(f\"Score Time: {score_time_nb}\")\n",
    "print(f\"Accuracy: {accuracy_nb}\")\n",
    "print(f\"F1 Score: {f1_nb}\")\n",
    "print(f\"Precision: {precision_nb}\")\n",
    "print(f\"Recall: {recall_nb}\")\n",
    "print(f\"ROC-AUC: {roc_auc_nb}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"K Nearest Neighbours:\")\n",
    "print(f\"Fit Time: {fit_time_knn}\")\n",
    "print(f\"Score Time: {score_time_knn}\")\n",
    "print(f\"Accuracy: {accuracy_knn}\")\n",
    "print(f\"F1 Score: {f1_knn}\")\n",
    "print(f\"Precision: {precision_knn}\")\n",
    "print(f\"Recall: {recall_knn}\")\n",
    "print(f\"ROC-AUC: {roc_auc_knn}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "# Print the results for Random Forest\n",
    "print(\"Random Forest:\")\n",
    "print(f\"Fit Time: {fit_time_rf}\")\n",
    "print(f\"Score Time: {score_time_rf}\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(f\"F1 Score: {f1_rf}\")\n",
    "print(f\"Precision: {precision_rf}\")\n",
    "print(f\"Recall: {recall_rf}\")\n",
    "print(f\"ROC-AUC: {roc_auc_rf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "classifiers = [\"Logistic Regression\", \"Naive Bayes\", \"K Nearest Neighbours\", \"Random Forest\"]\n",
    "fit_times = [fit_time_logreg, fit_time_nb, fit_time_knn, fit_time_rf]\n",
    "score_times = [score_time_logreg, score_time_nb, score_time_knn, score_time_rf]\n",
    "accuracies = [accuracy_logreg, accuracy_nb, accuracy_knn, accuracy_rf]\n",
    "f1_scores = [f1_logreg, f1_nb, f1_knn, f1_rf]\n",
    "precisions = [precision_logreg, precision_nb, precision_knn, precision_rf]\n",
    "recalls = [recall_logreg, recall_nb, recall_knn, recall_rf]\n",
    "roc_aucs = [roc_auc_logreg, roc_auc_nb, roc_auc_knn, roc_auc_rf]\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Classifier\", \"Fit Time (s)\", \"Score Time (s)\", \"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\", \"ROC-AUC\"]\n",
    "\n",
    "for data in zip(classifiers, fit_times, score_times, accuracies, f1_scores, precisions, recalls, roc_aucs):\n",
    "    table.add_row(data)\n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Logistic Regression\n",
    "logreg_classifier = LogisticRegression(random_state=42)\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "y_score_logreg = logreg_classifier.predict_proba(X_test)[:, 1]\n",
    "fpr_logreg, tpr_logreg, _ = roc_curve(y_test, y_score_logreg)\n",
    "roc_auc_logreg = auc(fpr_logreg, tpr_logreg)\n",
    "\n",
    "# Naive Bayes\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_score_nb = nb_classifier.predict_proba(X_test)[:, 1]\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test, y_score_nb)\n",
    "roc_auc_nb = auc(fpr_nb, tpr_nb)\n",
    "\n",
    "# K Nearest Neighbours\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "y_score_knn = knn_classifier.predict_proba(X_test)[:, 1]\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, y_score_knn)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_score_rf = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_score_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_logreg, tpr_logreg, label=f'Logistic Regression ')\n",
    "plt.plot(fpr_nb, tpr_nb, label=f'Naive Bayes')\n",
    "plt.plot(fpr_knn, tpr_knn, label=f'K Nearest Neighbours')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest')\n",
    "\n",
    "plt.title('ROC Curve for BollyBAIT Classifiers')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data summary:\")\n",
    "print(X_train.describe())\n",
    "\n",
    "print(\"\\nTesting data summary:\")\n",
    "print(X_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validtion to check for overfitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, learning_curve, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_folds = 5\n",
    "cross_val_scores = cross_val_score(model, X_train, y_train, cv=num_folds)\n",
    "\n",
    "mean_accuracy = np.mean(cross_val_scores)\n",
    "print(f'Mean Cross-Validation Accuracy: {mean_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorization =TfidfVectorizer()\n",
    "xv_train= vectorization.fit_transform(X_train)\n",
    "xv_test = vectorization.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_learning_curve(model, X, y, cv, train_sizes=np.linspace(0.1, 1.0, 5)):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=cv, train_sizes=train_sizes, scoring='accuracy')\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    print(train_sizes)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training Accuracy\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-Validation Accuracy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "plot_learning_curve(model, X_train, y_train, cv=num_folds)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)\n",
    "print(X_test.size)\n",
    "orig_arr=np.array(y_pred)\n",
    "y_pred_reshape = orig_arr.reshape(-1, 1)\n",
    "\n",
    "print(y_pred_reshape.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "decision_tree= DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHECKING FOR OVERFITTING!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "mean_score = np.mean(scores)\n",
    "std_score = np.std(scores)\n",
    "\n",
    "print(\"Cross-Validation Scores:\")\n",
    "print(scores)\n",
    "print(f\"Mean Accuracy: {mean_score:.2f}\")\n",
    "print(f\"Standard Deviation: {std_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 11, 20],\n",
    "    'min_samples_split': [1, 3, 5],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"best Hyperparameters:\")\n",
    "print(best_params)\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4087054,
     "sourceId": 7092131,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
